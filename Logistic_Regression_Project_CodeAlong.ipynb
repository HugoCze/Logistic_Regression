{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04682332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/Spark/spark-3.3.0-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "185c490c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/14 08:02:10 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Logistic_Regression_Test_CodeAlong').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7a4853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('customer_churn.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d1613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Churn: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82fea97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|summary|        Names|              Age|   Total_Purchase|   Account_Manager|            Years|         Num_Sites|            Location|             Company|              Churn|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "|  count|          900|              900|              900|               900|              900|               900|                 900|                 900|                900|\n",
      "|   mean|         null|41.81666666666667|10062.82403333334|0.4811111111111111| 5.27315555555555| 8.587777777777777|                null|                null|0.16666666666666666|\n",
      "| stddev|         null|6.127560416916251|2408.644531858096|0.4999208935073339|1.274449013194616|1.7648355920350969|                null|                null| 0.3728852122772358|\n",
      "|    min|   Aaron King|             22.0|            100.0|                 0|              1.0|               3.0|00103 Jeffrey Cre...|     Abbott-Thompson|                  0|\n",
      "|    max|Zachary Walsh|             65.0|         18026.01|                 1|             9.15|              14.0|Unit 9800 Box 287...|Zuniga, Clark and...|                  1|\n",
      "+-------+-------------+-----------------+-----------------+------------------+-----------------+------------------+--------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# According to the column counts we are not missing any data. That means we can skip the step of droping the Nan values as they\n",
    "# simply not there\n",
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc782bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Names',\n",
       " 'Age',\n",
       " 'Total_Purchase',\n",
       " 'Account_Manager',\n",
       " 'Years',\n",
       " 'Num_Sites',\n",
       " 'Onboard_date',\n",
       " 'Location',\n",
       " 'Company',\n",
       " 'Churn']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "530cba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5d2a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assiging colums to be converted to Vector colum values\n",
    "assembler = VectorAssembler(inputCols=[\n",
    " 'Age',\n",
    " 'Total_Purchase',\n",
    " 'Account_Manager',\n",
    " 'Years',\n",
    " 'Num_Sites'\n",
    "], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5aea7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By creating the output var we are assining the assembler vector values to out orginal dataset: data.\n",
    "output = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a7133f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Names='Cameron Williams', Age=42.0, Total_Purchase=11066.8, Account_Manager=0, Years=7.22, Num_Sites=8.0, Onboard_date=datetime.datetime(2013, 8, 30, 7, 0, 40), Location='10265 Elizabeth Mission Barkerburgh, AK 89518', Company='Harvey LLC', Churn=1, features=DenseVector([42.0, 11066.8, 0.0, 7.22, 8.0]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83cee32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are creating a variable containing predictions vector column from out recently transformed output dataset. And the \n",
    "# orginal churn column indicating state of our customer\n",
    "final_data = output.select('features', 'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c4d6001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=DenseVector([42.0, 11066.8, 0.0, 7.22, 8.0]), churn=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d7dbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_churn, test_churn = final_data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75d5522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c27f093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Logistic Regression Model\n",
    "lr_churn = LogisticRegression(labelCol='churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ed9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Logistic Regression Model into our splitted train data\n",
    "fitted_churn_model = lr_churn.fit(train_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62daad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating var containing the summary of fitted_churn_model. So Fitted Logistic Regression Model and our train data\n",
    "traning_sum = fitted_churn_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc55ee46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|              churn|         prediction|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|                621|                621|\n",
      "|   mean|0.16586151368760063|0.12721417069243157|\n",
      "| stddev| 0.3722561208365632|0.33348134472971436|\n",
      "|    min|                0.0|                0.0|\n",
      "|    max|                1.0|                1.0|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can observe some differences in mean and stddev\n",
    "traning_sum.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bd19db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bc3f2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing an evaluation to verify how much our test data matches with our train model \n",
    "pred_and_labels = fitted_churn_model.evaluate(test_churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b9f613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|churn|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[28.0,8670.98,0.0...|    0|[7.47506266410890...|[0.99943327113090...|       0.0|\n",
      "|[28.0,9090.43,1.0...|    0|[1.51046040937801...|[0.81912942946992...|       0.0|\n",
      "|[28.0,11128.95,1....|    0|[4.21917833672590...|[0.98550254134918...|       0.0|\n",
      "|[30.0,8403.78,1.0...|    0|[5.81226902680076...|[0.99701828070522...|       0.0|\n",
      "|[30.0,10744.14,1....|    1|[1.90243755885451...|[0.87016716052231...|       0.0|\n",
      "|[30.0,11575.37,1....|    1|[4.05394678135018...|[0.98294226773198...|       0.0|\n",
      "|[31.0,8829.83,1.0...|    0|[4.35393512734133...|[0.98730705956532...|       0.0|\n",
      "|[31.0,11297.57,1....|    1|[1.08811398532711...|[0.74802640640400...|       0.0|\n",
      "|[32.0,5756.12,0.0...|    0|[3.91321693603271...|[0.98041509508017...|       0.0|\n",
      "|[32.0,8011.38,0.0...|    0|[1.75238242724273...|[0.85225304377514...|       0.0|\n",
      "|[32.0,8575.71,0.0...|    0|[3.49020259265463...|[0.97040771414400...|       0.0|\n",
      "|[32.0,8617.98,1.0...|    1|[1.06050156469251...|[0.74278638329917...|       0.0|\n",
      "|[32.0,9036.27,0.0...|    0|[-0.3360504315399...|[0.41676919233732...|       1.0|\n",
      "|[32.0,11715.72,0....|    0|[3.24341515586508...|[0.96243577333348...|       0.0|\n",
      "|[32.0,12254.75,1....|    0|[2.67889331404420...|[0.93576963850216...|       0.0|\n",
      "|[33.0,10309.71,1....|    0|[6.20234645932624...|[0.99797941678042...|       0.0|\n",
      "|[33.0,10709.39,1....|    0|[6.30487597293316...|[0.99817596040196...|       0.0|\n",
      "|[33.0,13157.08,1....|    0|[1.54518451715471...|[0.82421713795496...|       0.0|\n",
      "|[34.0,5447.16,1.0...|    0|[3.18352738521505...|[0.96020965610393...|       0.0|\n",
      "|[34.0,7324.32,0.0...|    0|[0.98773514284097...|[0.72864033861546...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "645c9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a BinaryClassificationEvaluator on churn_eval var\n",
    "churn_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "606a2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assining BinaryClassificationEvaluator evaluation object to our pred_and_labels prediction col.\n",
    "auc = churn_eval.evaluate(pred_and_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a4bd02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699926632428468"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we are able to see the evaluation how in reality our prediction is sufficient \n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2168d0ef",
   "metadata": {},
   "source": [
    "# Prediction on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44d03d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final data used to construct the final_lr_model is just the churn column and the features vector column established b4.\n",
    "# Also the lr_churn is just the Logistic Regression set of values of churn col. \n",
    "final_lr_model = lr_churn.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee98619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customers = spark.read.csv('new_customers.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55acc8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_customers.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e4a7ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assining the previously created vector assembler values to new customers dataset\n",
    "test_new_customer = assembler.transform(new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "08de50f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Names: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Total_Purchase: double (nullable = true)\n",
      " |-- Account_Manager: integer (nullable = true)\n",
      " |-- Years: double (nullable = true)\n",
      " |-- Num_Sites: double (nullable = true)\n",
      " |-- Onboard_date: timestamp (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_new_customer.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b01c281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assining the previously created final_lr_model to new customers dataset\n",
    "final_results = final_lr_model.transform(test_new_customer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce6e9260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+\n",
      "|         Company|prediction|\n",
      "+----------------+----------+\n",
      "|        King Ltd|       0.0|\n",
      "|   Cannon-Benson|       1.0|\n",
      "|Barron-Robertson|       1.0|\n",
      "|   Sexton-Golden|       1.0|\n",
      "|        Wood LLC|       0.0|\n",
      "|   Parks-Robbins|       1.0|\n",
      "+----------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_results.select('Company','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807ae5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
